{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(7%32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hand detection \n",
    "mp_hands = mp.solutions.hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5, model_complexity=1, static_image_mode=False)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "pyautogui.FAILSAFE = False\n",
    "click_threshold = 0.1\n",
    "alpha = 0.5\n",
    "\n",
    "# define hand landmark to track\n",
    "\n",
    "# get screen size\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# sensitivity factor for cursor movement (adjust for desired speed)\n",
    "sensivity = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# Initialize previous landmark positions\n",
    "def swipe(landmarks):\n",
    "        if landmarks:\n",
    "            index_finger_tip = np.array([landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP].x, landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP].y])\n",
    "            wrist = np.array([landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x, landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y])\n",
    "\n",
    "            # Calculate the direction of the index finger\n",
    "            direction = index_finger_tip - wrist\n",
    "\n",
    "            # Check if the movement is mostly horizontal\n",
    "            if abs(direction[0]) > abs(direction[1]):\n",
    "                if direction[0] > 0:\n",
    "                    return 'right_swipe'\n",
    "                else:\n",
    "                    return 'left_swipe'\n",
    "\n",
    "    # Return None if no gesture is detected\n",
    "        return None\n",
    "    \n",
    "def perfrom_swipe(gesture):\n",
    "    if gesture == 'left_swipe':\n",
    "        pyautogui.mouseDown()\n",
    "        pyautogui.moveRel(-100, 0)\n",
    "        pyautogui.mouseUp()\n",
    "        pyautogui.moveTo(958, 404)\n",
    "        \n",
    "    if gesture == 'right_swipe':\n",
    "        pyautogui.mouseDown()\n",
    "        pyautogui.moveRel(100, 0)\n",
    "        pyautogui.mouseUp()\n",
    "        pyautogui.moveTo(958, 404)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def detect_hands(frame):\n",
    "  \"\"\"\n",
    "  Detects hands in a frame using MediaPipe.\n",
    "\n",
    "  Args:\n",
    "      frame: The frame to be processed.\n",
    "\n",
    "  Returns:\n",
    "      A list of hand landmarks if a hand is detected, otherwise None.\n",
    "  \"\"\"\n",
    "  rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB for MediaPipe\n",
    "  results = mp_hands.process(rgb_frame)\n",
    "  if results.multi_hand_landmarks:\n",
    "    hand_landmarks = results.multi_hand_landmarks[0]  # Assuming only one hand\n",
    "    return hand_landmarks\n",
    "  else:\n",
    "    return None\n",
    "  \n",
    "wrist_prev = None\n",
    "index_tip_prev = None\n",
    "thumb_tip_prev = None\n",
    "\n",
    "while True:\n",
    "  # Take a picture with the camera\n",
    "  success, frame = cap.read()\n",
    "\n",
    "  # 2. Spot the Tips (continued) - Find the fingertip in this picture\n",
    "  hand_landmarks = detect_hands(frame)  # This function is defined later\n",
    "  \n",
    "  # flip the frame \n",
    "  frame = cv2.flip(frame, 1)\n",
    "\n",
    "  # If we found a fingertip, let's move the cursor!\n",
    "  if hand_landmarks:\n",
    "    # Remember where the fingertip is now\n",
    "    mp_drawing.draw_landmarks(frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Remember where the fingertip is for next time\n",
    "    # prev_fingertip_x = smoothed_movement_x\n",
    "    # prev_fingertip_y = smoothed_movement_y\n",
    "    \n",
    "    # if is_left_click(hand_landmarks):\n",
    "    #     pyautogui.click(button='left')\n",
    "        \n",
    "    # if is_right_click(hand_landmarks):\n",
    "    #     pyautogui.click(button='right')\n",
    "         \n",
    "\n",
    "  # Show the picture with the fingertip (optional)\n",
    "  cv2.imshow('Hand', frame)\n",
    "\n",
    "  # Close the program if you press 'Esc'\n",
    "  if cv2.waitKey(5) & 0xFF == 27:\n",
    "    break\n",
    "\n",
    "# Clean up the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
