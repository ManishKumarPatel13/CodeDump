{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hand detection \n",
    "mp_hands = mp.solutions.hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5, model_complexity=1, static_image_mode=False)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "pyautogui.FAILSAFE = False\n",
    "click_threshold = 0.1\n",
    "alpha = 0.5\n",
    "\n",
    "# define hand landmark to track\n",
    "wrist_landmark_id = mp.solutions.hands.HandLandmark.WRIST\n",
    "index_landmark_id = mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP\n",
    "thumb_landmark_id = mp.solutions.hands.HandLandmark.THUMB_TIP\n",
    "middle_landmark_id = mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP\n",
    "\n",
    "def is_left_click(landmarks):\n",
    "    index_tip = landmarks.landmark[index_landmark_id]\n",
    "    thumb_tip = landmarks.landmark[thumb_landmark_id]\n",
    "    distance = np.sqrt((index_tip.x - thumb_tip.x) ** 2 + (index_tip.y - thumb_tip.y) ** 2)\n",
    "    return distance <= click_threshold\n",
    "\n",
    "def is_right_click(landmarks):\n",
    "    middle_tip = landmarks.landmark[middle_landmark_id]\n",
    "    thumb_tip = landmarks.landmark[thumb_landmark_id]\n",
    "    distance = np.sqrt((middle_tip.x - thumb_tip.x) ** 2 + (middle_tip.y - thumb_tip.y) ** 2)\n",
    "    return distance <= click_threshold\n",
    "\n",
    "def rotate_screen(landmarks):\n",
    "    index_tip = landmarks.landmark[index_landmark_id]\n",
    "    wrist = landmarks.landmark[wrist_landmark_id]\n",
    "    # print(f\"x: {(index_tip.y - index_tip.x)}\")\n",
    "    return (index_tip.x - wrist.x) < 0\n",
    "\n",
    "\n",
    "# get screen size\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# sensitivity factor for cursor movement (adjust for desired speed)\n",
    "sensivity = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# Initialize previous landmark positions\n",
    "prev_fingertip_x = 0\n",
    "prev_fingertip_y = 0\n",
    "\n",
    "def mouse_position(landmarks):\n",
    "    # index = 0.041\n",
    "    # middle = 0.26\n",
    "    # middlew = 0.1\n",
    "    indexw = 0\n",
    "    index_tip = landmarks.landmark[index_landmark_id]\n",
    "    # thumb_tip = landmarks.landmark[thumb_landmark_id]\n",
    "    middle_tip = landmarks.landmark[middle_landmark_id]\n",
    "    # ring_tip = landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_TIP]\n",
    "    # pinky_tip = landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "    \n",
    "    wrist = landmarks.landmark[wrist_landmark_id]\n",
    "    index_mcp = landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    index_pip = landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_PIP]\n",
    "    middle_pip = landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_PIP]\n",
    "    index_dip = landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_DIP]\n",
    "    middle_dip = landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_DIP]\n",
    "    # print(f\"TIP: {index_tip.x} MCP: {index_mcp.x} PIP: {index_pip.x} DIP: {index_dip.x}\")\n",
    "    print(index_tip.x - wrist.x)\n",
    "\n",
    "\n",
    "def cursor_movement(landmarks):\n",
    "    index_tip = landmarks.landmark[index_landmark_id]\n",
    "    movement_y = int(screen_height*index_tip.y)\n",
    "    movement_x = int(screen_width*index_tip.x)\n",
    "    \n",
    "    pyautogui.moveTo(movement_x, movement_y)\n",
    "    \n",
    "def screenshot(landmarks):\n",
    "    index_tip = landmarks.landmark[index_landmark_id]\n",
    "    wrist = landmarks.landmark[wrist_landmark_id]\n",
    "    middle_tip = landmarks.landmark[middle_landmark_id]\n",
    "    index = 0.61\n",
    "    middle = 0\n",
    "    \n",
    "    return (index_tip.x - wrist.x) < 0.61 and (middle_tip.x - wrist.x) < 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "def detect_hands(frame):\n",
    "  \"\"\"\n",
    "  Detects hands in a frame using MediaPipe.\n",
    "\n",
    "  Args:\n",
    "      frame: The frame to be processed.\n",
    "\n",
    "  Returns:\n",
    "      A list of hand landmarks if a hand is detected, otherwise None.\n",
    "  \"\"\"\n",
    "  rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB for MediaPipe\n",
    "  results = mp_hands.process(rgb_frame)\n",
    "  if results.multi_hand_landmarks:\n",
    "    hand_landmarks = results.multi_hand_landmarks[0]  # Assuming only one hand\n",
    "    return hand_landmarks\n",
    "  else:\n",
    "    return None\n",
    "  \n",
    "wrist_prev = None\n",
    "index_tip_prev = None\n",
    "thumb_tip_prev = None\n",
    "\n",
    "while True:\n",
    "  # Take a picture with the camera\n",
    "  success, frame = cap.read()\n",
    "\n",
    "  # 2. Spot the Tips (continued) - Find the fingertip in this picture\n",
    "  hand_landmarks = detect_hands(frame)  # This function is defined later\n",
    "  \n",
    "  # flip the frame \n",
    "  frame = cv2.flip(frame, 1)\n",
    "\n",
    "  # If we found a fingertip, let's move the cursor!\n",
    "  if hand_landmarks:\n",
    "    # Remember where the fingertip is now\n",
    "    # fingertip_landmark = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    mp_drawing.draw_landmarks(frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    cursor_movement(hand_landmarks)\n",
    "    \n",
    "    if screenshot(landmarks=hand_landmarks):\n",
    "      shot = pyautogui.screenshot()\n",
    "      shot.save(r'E:\\\\New folder\\\\CodeDump\\\\Python New Tut\\\\Machine Learning\\\\VirtualMouse\\\\screenshot.png')\n",
    "    \n",
    "  # Show the picture with the fingertip (optional)\n",
    "  cv2.imshow('Hand', frame)\n",
    "\n",
    "  # Close the program if you press 'Esc'\n",
    "  if cv2.waitKey(5) & 0xFF == 27:\n",
    "    break\n",
    "\n",
    "# Clean up the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXFK1RZRP4WN0EPK9JN95C58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
